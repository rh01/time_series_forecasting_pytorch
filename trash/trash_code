# 加载excel文件数据，选定时间轴和要预测的列名称
def load_data_xls(filename, indexName, columnName):

    df = pd.read_excel(filename, index_col=indexName)
    df.index = pd.to_datetime(df.index)
    df = df.fillna(method='pad')
    ts = df[columnName]
    data = pd.DataFrame(ts).values.reshape(-1)
    return ts, data


# 加载txt数据
def load_data_txt(filename, indexName, columnName):

    reader = pd.read_table(filename, header=0, index_col=indexName, delimiter=";", iterator=True)
    df = reader.get_chunk(5000)
    df.index = pd.to_datetime(df.index)
    #df = df.fillna(method='pad')
    ts = df[columnName]
    data = pd.DataFrame(ts).values.reshape(-1)
    return ts, data


# 变长度采样训练样本
'''
def createVariableDataset(dataset, minLen, maxLen,numInputs):
    dataX = []
    dataY = []
    for i in range(numInputs):
        start = np.random.randint(len(dataset)-minLen-1)
        #end = np.random.randint(min(start+minLen, len(dataset)-1), min(start+maxLen, len(dataset)-1))
        randomLen = np.random.randint(minLen, maxLen)
        if start+randomLen > len(dataset)-2:
            end = len(dataset)-2
        else:
            end = start+randomLen
        sequence_in = dataset[start:end]
        #sequence_in = pad_sequences(sequence_in, maxlen=maxLen, dtype='float32')
        sequence_out = dataset[end + 1]
        dataX.append(sequence_in)
        dataY.append(sequence_out)
    dataX = np.array(dataX)
    dataY = np.array(dataY)
    dataX = pad_sequences(dataX, maxlen=maxLen, dtype='float32') # 左端补齐
    dataX = np.reshape(dataX, (dataX.shape[0], dataX.shape[1], 1)) # 转化为rnn输入形式
    return dataX,dataY
'''

# # 取不同长度的子序列，以重点为基准点向前搜索出lag区间段的所有子序列
# def createVariableDataset(dataset, minLen, maxLen, step):
#
#     dataNum = len(dataset)
#     X,Y = [],[]
#
#     for i in range(maxLen, len(dataset)):
#         for lookBack in range(minLen, maxLen + 1, step):  # 遍历所有长度
#             a = dataset[i-lookBack:i]
#             X.append(a)
#             Y.append(dataset[i])
#     X = np.array(X)
#     Y = np.array(Y)
#     X = pad_sequences(X, maxlen=maxLen, dtype='float32')  # 左端补齐
#     X = np.reshape(X, (X.shape[0], X.shape[1], 1))
#     return X, Y
#
# # 将测试用的ground-truth转化为标准形式，与上面的函数一起使用
# def transformGroundTruth(vtestY, minLen, maxLen, step):
#
#     lagNum = (maxLen - minLen)//step+1
#     print("lag num is", lagNum)
#     truth = []
#     for i in range(0, len(vtestY), lagNum):
#         truth.append(np.mean(vtestY[i:i + lagNum]))
#     return np.array(truth)
#
#
# # 取不同长度样本并补足成最大长度
# def createPaddedDataset(dataset, lookBack, maxLen):
#
#     dataX, dataY = [], []
#     for i in range(len(dataset) - lookBack):
#         a = dataset[i:(i + lookBack)]
#         dataX.append(a)
#         dataY.append(dataset[i + lookBack])
#     dataX = np.array(dataX)
#     dataY = np.array(dataY)
#     dataX = pad_sequences(dataX, maxlen=maxLen, dtype='float32')  # 左端补齐
#     dataX = np.reshape(dataX, (dataX.shape[0], dataX.shape[1], 1))
#     return dataX, dataY



# 数据对齐
def align(trTrain,trTest,trendWin,resTrain,resTest,resWin):

    empWin = np.empty((trendWin))
    empWin[:] = np.nan

    empWin2 = np.empty((resWin))
    empWin2[:] = np.nan

    # empWinMax = np.empty((varMaxLen))
    # empWinMax[:] = np.nan

    trendPred = np.hstack((empWin, trTrain))

    trendPred = np.hstack((trendPred, empWin))
    trendPred = np.hstack((trendPred, trTest))

    resPred = np.hstack((empWin2, resTrain))
    resPred = np.hstack((resPred, empWin2))
    resPred = np.hstack((resPred, resTest))

    return trendPred,resPred


def plot(trainPred,trainY,testPred,testY):
    pred = np.concatenate((trainPred,testPred))
    gtruth = np.concatenate((trainY,testY))
    plt.plot(pred,'g')
    plt.plot(gtruth,'r')
    plt.show()


def LBtest(data):
    # lb,p = statsmodels.stats.diagnostic.acorr_ljungbox(residual)
    # print p
    r, q, p = sm.tsa.acf(data, qstat=True)
    data1 = np.c_[range(1, 41), r[1:], q, p]
    table = pd.DataFrame(data1, columns=['lag', "AC", "Q", "Prob(>Q)"])
    print(table.set_index('lag'))


def FCD_Train(ts, dataset, freq, lookBack, batchSize, epoch, lr, method):


    # 序列分解
    #ts.index = pd.date_range(start='19960318',periods=len(ts), freq='Q')
    trend, seasonal, residual = seasonDecompose(ts, freq)
    print("fcd decompose is finised!")
    print("trend shape is", trend.shape)
    print("season shape is", seasonal.shape)
    print("residual shape is", residual.shape)

    # 分别预测

    MODEL_PATH = "../model/ResRNN_model.pkl"
    # trainPred, testPred, MAE, MRSE, SMAPE = test(data=dataset, lookBack=lag, epoch=epoch,
    #                                              batchSize=batchSize, method=method, modelPath=MODEL_PATH)
    trTrain, trTest, MAE1, MRSE1, SMAPE1 = test(trend, lookBack, epoch, lr, batchSize,  method=method, modelPath=MODEL_PATH)
    resTrain, resTest, MAE2, MRSE2, SMAPE2 = test(residual, lookBack, epoch, lr, batchSize, method=method, modelPath=MODEL_PATH)
    # trTrain, trTest, MAE1, MRSE1, SMAPE1= RNNFORECAST.RNNforecasting(trend, lookBack=resWin, epoch=30, unit=unit,
    #                                                                     varFlag=True, minLen=20, maxLen=lag, step=4,
    #                                                                     hiddenNum=100)
    # resTrain, resTest, MAE2, MRSE2, SMAPE2 = RNNFORECAST.RNNforecasting(residual, lookBack=resWin, epoch=30, unit=unit,
    #                                                                     varFlag=True, minLen=20, maxLen=lag, step=4, hiddenNum=100)

    trTrain = trTrain.reshape(-1)
    trTest = trTest.reshape(-1)
    resTrain = resTrain.reshape(-1)
    resTest = resTest.reshape(-1)

    print("trTrain shape is", trTrain.shape)
    print("resTrain shape is", resTrain.shape)

    # '''
    # 数据对齐
    trendPred, resPred = align(trTrain, trTest, lookBack, resTrain, resTest, lookBack)

    print("trendPred shape is", trendPred.shape)
    print("resPred shape is", resPred.shape)

    # 获取最终预测结果
    finalPred = trendPred + seasonal + resPred

    trainPred = trTrain + seasonal[lookBack:lookBack + trTrain.shape[0]] + resTrain
    testPred = trTest + seasonal[2 * lookBack + resTrain.shape[0] :] + resTest

    # 获得ground-truth数据
    data = dataset[freq // 2:-(freq // 2)]
    trainY = data[lookBack:lookBack + trTrain.shape[0]]
    testY = data[2 * lookBack + resTrain.shape[0]:]
    print(trainY.shape)
    print(testY.shape)
    print(trainPred.shape)
    print(testPred.shape)

    # 评估指标
    MAE = eval.calcMAE(trainY, trainPred)
    print("train MAE", MAE)
    MRSE = eval.calcRMSE(trainY, trainPred)
    print("train MRSE", MRSE)
    MAPE = eval.calcMAPE(trainY, trainPred)
    print("train MAPE", MAPE)
    MAE = eval.calcMAE(testY, testPred)
    print("test MAE", MAE)
    MRSE = eval.calcRMSE(testY, testPred)
    print("test RMSE", MRSE)
    MAPE = eval.calcMAPE(testY, testPred)
    print("test MAPE", MAPE)
    SMAPE = eval.calcSMAPE(testY, testPred)
    print("test SMAPE", SMAPE)

    # plt.plot(data)
    # plt.plot(finalPred)
    # plt.show()
    # '''
    return trainPred, testPred, MAE, MRSE, SMAPE


def FCD_Train_SVM(ts, dataset, freq, lookBack):


    # 序列分解
    #ts.index = pd.date_range(start='19960318',periods=len(ts), freq='Q')
    trend, seasonal, residual = seasonDecompose(ts, freq)
    print("fcd decompose is finised!")
    print("trend shape is", trend.shape)
    print("season shape is", seasonal.shape)
    print("residual shape is", residual.shape)

    # 分别预测

    trTrain, trTest, MAE1, MRSE1, SMAPE1 = testSVM(trend, lookBack)
    resTrain, resTest, MAE2, MRSE2, SMAPE2 = testSVM(residual, lookBack)

    trTrain = trTrain.reshape(-1)
    trTest = trTest.reshape(-1)
    resTrain = resTrain.reshape(-1)
    resTest = resTest.reshape(-1)

    print("trTrain shape is", trTrain.shape)
    print("resTrain shape is", resTrain.shape)

    # 数据对齐
    trendPred, resPred = align(trTrain, trTest, lookBack, resTrain, resTest, lookBack)

    print("trendPred shape is", trendPred.shape)
    print("resPred shape is", resPred.shape)

    # 获取最终预测结果
    finalPred = trendPred + seasonal + resPred

    trainPred = trTrain + seasonal[lookBack:lookBack + trTrain.shape[0]] + resTrain
    testPred = trTest + seasonal[2 * lookBack + resTrain.shape[0] :] + resTest

    # 获得ground-truth数据
    data = dataset[freq // 2:-(freq // 2)]
    trainY = data[lookBack:lookBack + trTrain.shape[0]]
    testY = data[2 * lookBack + resTrain.shape[0]:]
    print(trainY.shape)
    print(testY.shape)
    print(trainPred.shape)
    print(testPred.shape)

    # 评估指标
    MAE = eval.calcMAE(trainY, trainPred)
    print("train MAE", MAE)
    MRSE = eval.calcRMSE(trainY, trainPred)
    print("train MRSE", MRSE)
    MAPE = eval.calcMAPE(trainY, trainPred)
    print("train MAPE", MAPE)
    MAE = eval.calcMAE(testY, testPred)
    print("test MAE", MAE)
    MRSE = eval.calcRMSE(testY, testPred)
    print("test RMSE", MRSE)
    MAPE = eval.calcMAPE(testY, testPred)
    print("test MAPE", MAPE)
    SMAPE = eval.calcSMAPE(testY, testPred)
    print("test SMAPE", SMAPE)

    # plt.plot(data)
    # plt.plot(finalPred)
    # plt.show()
    # '''
    return trainPred, testPred, MAE, MRSE, SMAPE


# 分解网络
class DecompositionNetModel(nn.Module):

    def __init__(self, inputDim, fchiddenNum, rnnhiddenNum, outputDim):

        super(DecompositionNetModel, self).__init__()
        self.fchiddenNum = fchiddenNum
        self.rnnhiddenNum = rnnhiddenNum
        self.inputDim = inputDim
        self.outputDim = outputDim
        self.layerNum = 1
        self.rnnInputDim = 1

        # dropout层
        self.drop = nn.Dropout(p=0.3)

        # 一维卷积层
        self.conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5, stride=1, padding=2,  bias=True)
        self.pool = nn.AvgPool1d(kernel_size=5, stride=1, padding=2)
        #self.conv.weight.data.fill_(0.2)
        self.convWeight = self.conv.weight.data
        #print(self.conv.weight.data)

        # 全连接层
        self.fc1 = nn.Linear(self.inputDim, self.fchiddenNum)
        self.fc2 = nn.Linear(self.fchiddenNum, self.inputDim)

        # 循环神经网络层
        self.rnn1 = nn.RNN(input_size=self.rnnInputDim, hidden_size=self.rnnhiddenNum,
                           num_layers=self.layerNum, dropout=0.5,
                           nonlinearity="tanh", batch_first=True, )
        self.rnn2 = nn.RNN(input_size=self.rnnInputDim, hidden_size=self.rnnhiddenNum,
                          num_layers=self.layerNum, dropout=0.5,
                          nonlinearity="tanh", batch_first=True, )
        self.resrnn1 = ResRNNModel(inputDim=1, hiddenNum=self.rnnhiddenNum, outputDim=1, resDepth=4)
        self.resrnn2 = ResRNNModel(inputDim=1, hiddenNum=self.rnnhiddenNum, outputDim=1, resDepth=4 )
        self.gru1 = nn.GRU(input_size=self.rnnInputDim, hidden_size=self.rnnhiddenNum,
                           num_layers=self.layerNum, dropout=0.0,
                           batch_first=True, )
        self.gru2 = nn.GRU(input_size=self.rnnInputDim, hidden_size=self.rnnhiddenNum,
                           num_layers=self.layerNum, dropout=0.0,
                           batch_first=True, )

        # 线性输出层
        self.fc3 = nn.Linear(self.rnnhiddenNum, self.outputDim)
        self.fc4 = nn.Linear(self.rnnhiddenNum, self.outputDim)

    def forward(self, x, batchSize):

        # 分解网络
        x = torch.unsqueeze(x, 1)
        #print(x.size())
        #x = torch.transpose(x, 1, 2)
        # output = self.fc1(x)
        # prime = self.fc2(output)
        prime = self.conv(x)
        #print(prime.size())
        prime = self.pool(prime)
        #print(prime.size())
        residual = x-prime
        # prime = torch.unsqueeze(prime, 2)
        # residual = torch.unsqueeze(residual, 2)
        prime = torch.transpose(prime, 1, 2)
        residual = torch.transpose(residual, 1, 2)

        h0 = Variable(torch.zeros(self.layerNum * 1, batchSize, self.rnnhiddenNum))

        # 预测主成分rnn网络
        rnnOutput1, hn1 = self.gru1(prime, h0)  # rnnOutput 12,20,50 hn 1,20,50
        hn1 = hn1.view(batchSize, self.rnnhiddenNum)
        #hn1 = self.drop(hn1)
        fcOutput1 = self.fc3(hn1)
        #fcOutput1 = self.resrnn1.forward(prime, batchSize=batchSize)

        # 预测残差rnn网络
        rnnOutput2, hn2 = self.gru2(residual, h0)  # rnnOutput 12,20,50 hn 1,20,50
        hn2 = hn2.view(batchSize, self.rnnhiddenNum)
        #hn2 = self.drop(hn2)
        fcOutput2 = self.fc4(hn2)
        #fcOutput2 = self.resrnn2.forward(prime, batchSize=batchSize)

        # 合并预测结果
        result = fcOutput1+fcOutput2

        return result, fcOutput1, fcOutput2, residual

